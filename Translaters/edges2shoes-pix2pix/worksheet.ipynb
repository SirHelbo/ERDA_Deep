{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "     \n",
    "def read_image(image):\n",
    "         \n",
    "        image = np.array(image)\n",
    "        width = image.shape[1]\n",
    "        width_half = width // 2\n",
    "        \n",
    "        input_image = image[:, :width_half, :]\n",
    "        target_image = image[:, width_half:, :]\n",
    "     \n",
    "        input_image = input_image.astype(np.float32)\n",
    "        target_image = target_image.astype(np.float32)\n",
    "     \n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def random_crop(image, dim):\n",
    "    height, width, _ = dim\n",
    "    x, y = np.random.uniform(low=0,high=int(height-256)), np.random.uniform(low=0,high=int(width-256))  \n",
    "    return image[:, int(x):int(x)+256, int(y):int(y)+256]\n",
    " \n",
    "     \n",
    " \n",
    "def random_jittering_mirroring(input_image, target_image, height=286, width=286):\n",
    "     \n",
    "    #resizing to 286x286\n",
    "    input_image = cv2.resize(input_image, (height, width) ,interpolation=cv2.INTER_NEAREST)\n",
    "    target_image = cv2.resize(target_image, (height, width),\n",
    "                               interpolation=cv2.INTER_NEAREST)\n",
    "     \n",
    "    #cropping (random jittering) to 256x256\n",
    "    stacked_image = np.stack([input_image, target_image], axis=0)\n",
    "    cropped_image = random_crop(stacked_image, dim=[256, 256, 3])\n",
    "     \n",
    "    input_image, target_image = cropped_image[0], cropped_image[1]\n",
    "    #print(input_image.shape)\n",
    "    if torch.rand(()) > 0.5:\n",
    "     # random mirroring\n",
    "        input_image = np.fliplr(input_image)\n",
    "        target_image = np.fliplr(target_image)\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inp, tar):\n",
    "    input_image = (inp / 127.5) - 1\n",
    "    target_image = (tar / 127.5) - 1\n",
    "    return input_image, target_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(object):\n",
    "    def __call__(self, image):\n",
    "        inp, tar = read_image(image)\n",
    "        inp, tar = random_jittering_mirroring(inp, tar)\n",
    "        inp, tar = normalize(inp, tar)\n",
    "        image_a = torch.from_numpy(inp.copy().transpose((2,0,1)))\n",
    "        image_b = torch.from_numpy(tar.copy().transpose((2,0,1)))\n",
    "        return image_a, image_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2BD1B165-EC09-3F68-BCE4-8FE4E70CA7E2> /opt/homebrew/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <44DEDA27-4DE9-3D4A-8EDE-5AA72081319F> /opt/homebrew/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "DIR = 'edges2shoes/train/'\n",
    "n_gpus = 4\n",
    "batch_size = 64\n",
    "global_batch_size = batch_size * n_gpus\n",
    " \n",
    "train_ds = ImageFolder(DIR, transform=transforms.Compose([\n",
    "        Train()]))\n",
    "train_dl = DataLoader(train_ds, global_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on generator and discriminator\n",
    "def init_weights(net, init_type='normal', scaling=0.02):\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv')) != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 0.0, scaling)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, scaling)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    " \n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    " \n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    " \n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    " \n",
    "        self.model = nn.Sequential(*model)\n",
    " \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Create a Unet-based generator\"\"\"\n",
    " \n",
    "    def __init__(self, input_nc, output_nc, nf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        # add the innermost block\n",
    "        unet_block = UnetSkipConnectionBlock(nf * 8, nf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True) \n",
    "        #print(unet_block)\n",
    " \n",
    "        # add intermediate block with nf * 8 filters\n",
    "        unet_block = UnetSkipConnectionBlock(nf * 8, nf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = UnetSkipConnectionBlock(nf * 8, nf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = UnetSkipConnectionBlock(nf * 8, nf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    " \n",
    "        # gradually reduce the number of filters from nf * 8 to nf. \n",
    "        unet_block = UnetSkipConnectionBlock(nf * 4, nf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(nf * 2, nf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(nf, nf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "         \n",
    "        # add the outermost block\n",
    "        self.model = UnetSkipConnectionBlock(output_nc, nf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  \n",
    " \n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "# generator = UnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False).cuda().float()\n",
    "generator = UnetGenerator(3, 3, 64, use_dropout=False).float()\n",
    "generator.to(device)\n",
    "init_weights(generator, 'normal', scaling=0.02)\n",
    "generator = torch.nn.DataParallel(generator)  # multi-GPUs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=False),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    " \n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=False),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    " \n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw), nn.Sigmoid()]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    " \n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss() \n",
    "l1_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated_image, target_img, G, real_target):\n",
    "    gen_loss = adversarial_loss(G, real_target)\n",
    "    l1_l = l1_loss(generated_image, target_img)\n",
    "    gen_total_loss = gen_loss + (100 * l1_l)\n",
    "    #print(gen_loss)\n",
    "    return gen_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(output, label):\n",
    "    disc_loss = adversarial_loss(output, label)\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator(6)\n",
    "discriminator.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "D_optimizer = optim.Adam(discriminator.parameters(), lr=0.001, eps=0.1) \n",
    "\n",
    "G_optimizer = optim.Adam(generator.parameters(), lr=0.001, eps=0.1) \n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "D_loss_plot, G_loss_plot = [], []\n",
    "for epoch in range(1, num_epochs+1): \n",
    "   \n",
    "    print(f\"Epoch {epoch}\")\n",
    " \n",
    "    D_loss_list, G_loss_list = [], []\n",
    "    \n",
    "    \n",
    "    for (input_img, target_img), _ in train_dl:\n",
    "        \n",
    "        D_optimizer.zero_grad()\n",
    "        input_img = input_img.to(device)\n",
    "        target_img = target_img.to(device)\n",
    " \n",
    "        # ground truth labels real and fake\n",
    "        real_target = torch.ones(input_img.size(0), 1, 30, 30).to(device)\n",
    "        fake_target = torch.zeros(input_img.size(0), 1, 30, 30).to(device)\n",
    "         \n",
    "        # generator forward pass\n",
    "        generated_image = generator(input_img)\n",
    "         \n",
    "        # train discriminator with fake/generated images\n",
    "        disc_inp_fake = torch.cat((input_img, generated_image), 1)\n",
    "         \n",
    "        D_fake = discriminator(disc_inp_fake.detach())\n",
    "         \n",
    "        D_fake_loss   =  discriminator_loss(D_fake, fake_target)\n",
    "         \n",
    "        # train discriminator with real images\n",
    "        disc_inp_real = torch.cat((input_img, target_img), 1)\n",
    "                                 \n",
    "        D_real = discriminator(disc_inp_real)\n",
    "        D_real_loss = discriminator_loss(D_real,  real_target)\n",
    " \n",
    "     \n",
    "         \n",
    "        # average discriminator loss\n",
    "        D_total_loss = (D_real_loss + D_fake_loss) / 2\n",
    "        D_loss_list.append(D_total_loss)\n",
    "        # compute gradients and run optimizer step\n",
    "        D_total_loss.backward()\n",
    "        D_optimizer.step()\n",
    "         \n",
    "         \n",
    "        # Train generator with real labels\n",
    "        G_optimizer.zero_grad()\n",
    "        fake_gen = torch.cat((input_img, generated_image), 1)\n",
    "        G = discriminator(fake_gen)\n",
    "        G_loss = generator_loss(generated_image, target_img, G, real_target)                                 \n",
    "        G_loss_list.append(G_loss)\n",
    "        # compute gradients and run optimizer step\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (inputs, targets), _ in val_dl:\n",
    "    inputs = inputs.to(device)\n",
    "    generated_output =  generator(inputs)\n",
    "    save_images(generated_output.data[:10], 'sample_%d'%epoch + '.png', nrow=5, normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Aug 24 2023, 15:09:45) [Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
